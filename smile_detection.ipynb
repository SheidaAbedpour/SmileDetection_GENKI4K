{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFmWmS1qXHF7"
      },
      "outputs": [],
      "source": [
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g0df7qcIXR03"
      },
      "outputs": [],
      "source": [
        "from deepface import DeepFace\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YO68mCx8XRp5"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip the uploaded faces.zip file\n",
        "with zipfile.ZipFile(\"faces.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"faces\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JbYnbnB4s2ak"
      },
      "outputs": [],
      "source": [
        "# List image files and read labels\n",
        "faces_dir = \"/content/faces\"\n",
        "labels_path = \"/content/labels.txt\"\n",
        "\n",
        "image_files = sorted(glob.glob(os.path.join(faces_dir, \"*.jpg\")))\n",
        "\n",
        "# Load labels from labels.txt\n",
        "labels = []\n",
        "with open(labels_path, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split()\n",
        "        label = int(parts[0])\n",
        "        labels.append(label)\n",
        "\n",
        "# Split images and labels into training and testing sets\n",
        "train_files, test_files, y_train, y_test = train_test_split(\n",
        "    image_files, labels, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "train_files, val_files, y_train, y_val = train_test_split(\n",
        "    train_files, y_train, test_size=0.1, random_state=42, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPOOJxjWYX8K",
        "outputId": "cc6fb044-c8f5-4f4e-81da-ee7b4b55dacb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train embeddings shape: (2880, 4096)\n",
            "Validation embeddings shape: (320, 4096)\n",
            "Test embeddings shape: (800, 4096)\n"
          ]
        }
      ],
      "source": [
        "# Function to generate embeddings\n",
        "def generate_embeddings(image_paths, labels):\n",
        "    embeddings = []\n",
        "\n",
        "    # Process each image and extract embeddings\n",
        "    for path in image_paths:\n",
        "        # Read and preprocess image\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "        img = cv2.resize(img, (160, 160))  # Resize to input size\n",
        "        img = img.astype(\"float32\") / 255.0  # Normalize image\n",
        "\n",
        "        # Extract embeddings using DeepFace\n",
        "        result = DeepFace.represent(img_path=path, model_name=\"VGG-Face\", enforce_detection=False)\n",
        "        if result:\n",
        "            embeddings.append(np.array(result[0][\"embedding\"]))\n",
        "        else:\n",
        "            print(f\"Face not detected in {path}\")\n",
        "\n",
        "    return np.array(embeddings)\n",
        "\n",
        "\n",
        "# Generate embeddings\n",
        "X_train_embeddings = generate_embeddings(train_files, y_train)\n",
        "X_val_embeddings = generate_embeddings(val_files, y_val)\n",
        "X_test_embeddings = generate_embeddings(test_files, y_test)\n",
        "\n",
        "print(f\"Train embeddings shape: {X_train_embeddings.shape}\")\n",
        "print(f\"Validation embeddings shape: {X_val_embeddings.shape}\")\n",
        "print(f\"Test embeddings shape: {X_test_embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zU60n7GHr9mv"
      },
      "outputs": [],
      "source": [
        "# Convert labels to NumPy arrays\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO2iFsLjeBqR",
        "outputId": "ed7027cc-0874-4d22-acac-f06d5b8fe3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 10s 101ms/step - loss: 0.6801 - accuracy: 0.5684 - val_loss: 0.6425 - val_accuracy: 0.6844\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 8s 85ms/step - loss: 0.5425 - accuracy: 0.7976 - val_loss: 0.3746 - val_accuracy: 0.8844\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 9s 102ms/step - loss: 0.3090 - accuracy: 0.8851 - val_loss: 0.2432 - val_accuracy: 0.8969\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 8s 88ms/step - loss: 0.2213 - accuracy: 0.9174 - val_loss: 0.2066 - val_accuracy: 0.9375\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 9s 100ms/step - loss: 0.1811 - accuracy: 0.9326 - val_loss: 0.1962 - val_accuracy: 0.9156\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 8s 91ms/step - loss: 0.1432 - accuracy: 0.9538 - val_loss: 0.1948 - val_accuracy: 0.9250\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 9s 101ms/step - loss: 0.1155 - accuracy: 0.9622 - val_loss: 0.1934 - val_accuracy: 0.9250\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 7s 76ms/step - loss: 0.0936 - accuracy: 0.9726 - val_loss: 0.2010 - val_accuracy: 0.9187\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 9s 101ms/step - loss: 0.0720 - accuracy: 0.9833 - val_loss: 0.2098 - val_accuracy: 0.9312\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 8s 93ms/step - loss: 0.0539 - accuracy: 0.9861 - val_loss: 0.2133 - val_accuracy: 0.9219\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 0.2736 - accuracy: 0.9013\n",
            "Test Accuracy: 90.13%\n"
          ]
        }
      ],
      "source": [
        "# Build a neural network classifier\n",
        "classifier = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(4096,)),  # Input layer for VGG-Face embeddings\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary output for smile/non-smile\n",
        "])\n",
        "\n",
        "learning_rate = 1e-5 * 5\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile the model with the custom learning rate\n",
        "classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = classifier.fit(X_train_embeddings, y_train,\n",
        "                         epochs=10,\n",
        "                         batch_size=32,\n",
        "                         validation_data=(X_val_embeddings, y_val))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = classifier.evaluate(X_test_embeddings, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuZWtLckhWYv"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "classifier.save('/content/smile_non_smile_classifier.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TiIxEUggtQJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}