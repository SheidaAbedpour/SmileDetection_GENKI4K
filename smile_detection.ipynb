{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMs6dpjtQwu3vwD702+xRMV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFmWmS1qXHF7"
      },
      "outputs": [],
      "source": [
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "g0df7qcIXR03"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip the uploaded faces.zip file\n",
        "with zipfile.ZipFile(\"faces.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"faces\")"
      ],
      "metadata": {
        "id": "YO68mCx8XRp5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List image files and read labels\n",
        "faces_dir = \"/content/faces\"\n",
        "labels_path = \"/content/labels.txt\"\n",
        "\n",
        "image_files = sorted(glob.glob(os.path.join(faces_dir, \"*.jpg\")))\n",
        "\n",
        "# Load labels from labels.txt\n",
        "labels = []\n",
        "with open(labels_path, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split()\n",
        "        label = int(parts[0])\n",
        "        labels.append(label)\n",
        "\n",
        "# Split images and labels into training and testing sets\n",
        "train_files, test_files, y_train, y_test = train_test_split(\n",
        "    image_files, labels, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "train_files, val_files, y_train, y_val = train_test_split(\n",
        "    train_files, y_train, test_size=0.1, random_state=42, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "JbYnbnB4s2ak"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(file_list):\n",
        "    images = []\n",
        "    for file in file_list:\n",
        "        img = cv2.imread(file)\n",
        "\n",
        "        # Resize to FaceNet512 input\n",
        "        img = cv2.resize(img, (160, 160))\n",
        "\n",
        "        # Normalize\n",
        "        img = img.astype(\"float32\") / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Preprocess the images\n",
        "X_train = preprocess_images(train_files)\n",
        "X_val = preprocess_images(val_files)\n",
        "X_test = preprocess_images(test_files)"
      ],
      "metadata": {
        "id": "NrukJt1hF7zM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate embeddings\n",
        "def generate_embeddings(image_paths, labels):\n",
        "    embeddings = []\n",
        "\n",
        "    # Process each image and extract embeddings\n",
        "    for path in image_paths:\n",
        "        # Read and preprocess image\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "        img = cv2.resize(img, (160, 160))  # Resize to FaceNet input size\n",
        "        img = img.astype(\"float32\") / 255.0  # Normalize image\n",
        "\n",
        "        # Extract embeddings using DeepFace\n",
        "        result = DeepFace.represent(img_path=path, model_name=\"Facenet512\", enforce_detection=False)\n",
        "        if result:\n",
        "            embeddings.append(np.array(result[0][\"embedding\"]))\n",
        "        else:\n",
        "            print(f\"Face not detected in {path}\")\n",
        "\n",
        "    return np.array(embeddings)\n",
        "\n",
        "\n",
        "# Generate embeddings\n",
        "X_train_embeddings = generate_embeddings(train_files, y_train)\n",
        "X_val_embeddings = generate_embeddings(val_files, y_val)\n",
        "X_test_embeddings = generate_embeddings(test_files, y_test)\n",
        "\n",
        "print(f\"Train embeddings shape: {X_train_embeddings.shape}\")\n",
        "print(f\"Validation embeddings shape: {X_val_embeddings.shape}\")\n",
        "print(f\"Test embeddings shape: {X_test_embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPOOJxjWYX8K",
        "outputId": "a0fdf9cc-7295-4ddd-e3d4-60e63fb27256"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train embeddings shape: (2880, 512)\n",
            "Validation embeddings shape: (320, 512)\n",
            "Test embeddings shape: (800, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to NumPy arrays\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "zU60n7GHr9mv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network classifier\n",
        "classifier = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(512,)),  # Input layer for Facenet512 embeddings\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary output for smile/non-smile\n",
        "])\n",
        "\n",
        "learning_rate = 1e-5\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile the model with the custom learning rate\n",
        "classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = classifier.fit(X_train_embeddings, y_train,\n",
        "                         epochs=60,\n",
        "                         batch_size=32,\n",
        "                         validation_data=(X_val_embeddings, y_val))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = classifier.evaluate(X_test_embeddings, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO2iFsLjeBqR",
        "outputId": "875ea29d-966a-4521-820a-3e710eb59350"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "90/90 [==============================] - 2s 9ms/step - loss: 0.7598 - accuracy: 0.5260 - val_loss: 0.6834 - val_accuracy: 0.5969\n",
            "Epoch 2/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.6716 - accuracy: 0.5983 - val_loss: 0.6289 - val_accuracy: 0.6438\n",
            "Epoch 3/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.6271 - accuracy: 0.6486 - val_loss: 0.5966 - val_accuracy: 0.6844\n",
            "Epoch 4/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5964 - accuracy: 0.6844 - val_loss: 0.5780 - val_accuracy: 0.7188\n",
            "Epoch 5/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5814 - accuracy: 0.6955 - val_loss: 0.5662 - val_accuracy: 0.7281\n",
            "Epoch 6/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5631 - accuracy: 0.7111 - val_loss: 0.5571 - val_accuracy: 0.7312\n",
            "Epoch 7/60\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.7260 - val_loss: 0.5514 - val_accuracy: 0.7312\n",
            "Epoch 8/60\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7312 - val_loss: 0.5474 - val_accuracy: 0.7250\n",
            "Epoch 9/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.7323 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
            "Epoch 10/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5282 - accuracy: 0.7319 - val_loss: 0.5412 - val_accuracy: 0.7312\n",
            "Epoch 11/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5214 - accuracy: 0.7403 - val_loss: 0.5397 - val_accuracy: 0.7375\n",
            "Epoch 12/60\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.5162 - accuracy: 0.7424 - val_loss: 0.5369 - val_accuracy: 0.7406\n",
            "Epoch 13/60\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7552 - val_loss: 0.5356 - val_accuracy: 0.7406\n",
            "Epoch 14/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5087 - accuracy: 0.7542 - val_loss: 0.5346 - val_accuracy: 0.7375\n",
            "Epoch 15/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5045 - accuracy: 0.7535 - val_loss: 0.5335 - val_accuracy: 0.7344\n",
            "Epoch 16/60\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.5037 - accuracy: 0.7611 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
            "Epoch 17/60\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4993 - accuracy: 0.7681 - val_loss: 0.5312 - val_accuracy: 0.7375\n",
            "Epoch 18/60\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4885 - accuracy: 0.7642 - val_loss: 0.5323 - val_accuracy: 0.7344\n",
            "Epoch 19/60\n",
            "90/90 [==============================] - 1s 13ms/step - loss: 0.4937 - accuracy: 0.7628 - val_loss: 0.5297 - val_accuracy: 0.7281\n",
            "Epoch 20/60\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4833 - accuracy: 0.7639 - val_loss: 0.5297 - val_accuracy: 0.7250\n",
            "Epoch 21/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4841 - accuracy: 0.7632 - val_loss: 0.5291 - val_accuracy: 0.7250\n",
            "Epoch 22/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4834 - accuracy: 0.7712 - val_loss: 0.5286 - val_accuracy: 0.7219\n",
            "Epoch 23/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4754 - accuracy: 0.7757 - val_loss: 0.5292 - val_accuracy: 0.7219\n",
            "Epoch 24/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4730 - accuracy: 0.7736 - val_loss: 0.5277 - val_accuracy: 0.7250\n",
            "Epoch 25/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.7712 - val_loss: 0.5269 - val_accuracy: 0.7219\n",
            "Epoch 26/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4679 - accuracy: 0.7806 - val_loss: 0.5256 - val_accuracy: 0.7281\n",
            "Epoch 27/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4655 - accuracy: 0.7788 - val_loss: 0.5257 - val_accuracy: 0.7250\n",
            "Epoch 28/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4645 - accuracy: 0.7774 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
            "Epoch 29/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4606 - accuracy: 0.7892 - val_loss: 0.5242 - val_accuracy: 0.7219\n",
            "Epoch 30/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4535 - accuracy: 0.7889 - val_loss: 0.5244 - val_accuracy: 0.7219\n",
            "Epoch 31/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4540 - accuracy: 0.7892 - val_loss: 0.5234 - val_accuracy: 0.7250\n",
            "Epoch 32/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4515 - accuracy: 0.7906 - val_loss: 0.5238 - val_accuracy: 0.7250\n",
            "Epoch 33/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4501 - accuracy: 0.7875 - val_loss: 0.5227 - val_accuracy: 0.7219\n",
            "Epoch 34/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4478 - accuracy: 0.7937 - val_loss: 0.5232 - val_accuracy: 0.7219\n",
            "Epoch 35/60\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4482 - accuracy: 0.7892 - val_loss: 0.5232 - val_accuracy: 0.7219\n",
            "Epoch 36/60\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4422 - accuracy: 0.7924 - val_loss: 0.5219 - val_accuracy: 0.7219\n",
            "Epoch 37/60\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4461 - accuracy: 0.7892 - val_loss: 0.5223 - val_accuracy: 0.7219\n",
            "Epoch 38/60\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5206 - val_accuracy: 0.7281\n",
            "Epoch 39/60\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5198 - val_accuracy: 0.7281\n",
            "Epoch 40/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.7997 - val_loss: 0.5202 - val_accuracy: 0.7312\n",
            "Epoch 41/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.8049 - val_loss: 0.5199 - val_accuracy: 0.7250\n",
            "Epoch 42/60\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4292 - accuracy: 0.8010 - val_loss: 0.5199 - val_accuracy: 0.7219\n",
            "Epoch 43/60\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.8031 - val_loss: 0.5203 - val_accuracy: 0.7281\n",
            "Epoch 44/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4258 - accuracy: 0.8069 - val_loss: 0.5199 - val_accuracy: 0.7281\n",
            "Epoch 45/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4219 - accuracy: 0.8087 - val_loss: 0.5201 - val_accuracy: 0.7281\n",
            "Epoch 46/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4229 - accuracy: 0.8062 - val_loss: 0.5194 - val_accuracy: 0.7250\n",
            "Epoch 47/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4202 - accuracy: 0.8062 - val_loss: 0.5200 - val_accuracy: 0.7312\n",
            "Epoch 48/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4192 - accuracy: 0.8101 - val_loss: 0.5192 - val_accuracy: 0.7281\n",
            "Epoch 49/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4146 - accuracy: 0.8153 - val_loss: 0.5192 - val_accuracy: 0.7250\n",
            "Epoch 50/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4148 - accuracy: 0.8174 - val_loss: 0.5178 - val_accuracy: 0.7219\n",
            "Epoch 51/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4127 - accuracy: 0.8069 - val_loss: 0.5198 - val_accuracy: 0.7219\n",
            "Epoch 52/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4152 - accuracy: 0.8111 - val_loss: 0.5187 - val_accuracy: 0.7312\n",
            "Epoch 53/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4083 - accuracy: 0.8212 - val_loss: 0.5176 - val_accuracy: 0.7312\n",
            "Epoch 54/60\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4070 - accuracy: 0.8125 - val_loss: 0.5169 - val_accuracy: 0.7281\n",
            "Epoch 55/60\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.4034 - accuracy: 0.8201 - val_loss: 0.5173 - val_accuracy: 0.7312\n",
            "Epoch 56/60\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4054 - accuracy: 0.8219 - val_loss: 0.5163 - val_accuracy: 0.7312\n",
            "Epoch 57/60\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4008 - accuracy: 0.8229 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
            "Epoch 58/60\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.3991 - accuracy: 0.8288 - val_loss: 0.5171 - val_accuracy: 0.7281\n",
            "Epoch 59/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4024 - accuracy: 0.8212 - val_loss: 0.5161 - val_accuracy: 0.7281\n",
            "Epoch 60/60\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4027 - accuracy: 0.8226 - val_loss: 0.5163 - val_accuracy: 0.7312\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7650\n",
            "Test Accuracy: 76.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "classifier.save('/content/smile_non_smile_classifier.h5')"
      ],
      "metadata": {
        "id": "zuZWtLckhWYv"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x35Ew5BYyaEN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}